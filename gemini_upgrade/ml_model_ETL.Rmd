---
title: "ML Model ETL & Feature Engineering (Hourly with Demand)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(feather)
library(ggplot2)
library(lubridate)
library(tidyr)
library(IAPWS95)
library(pracma)
```

## Load and Process Data

```{r load-process}
# Load the backup data
dt <- feather::read_feather("/home/dsl/gemini/chrust_plus/gemini_upgrade/model_df.feather")

# Aggregate to hourly averages
dt_hourly <- dt %>%
  group_by(date = floor_date(date, unit = "hour")) %>%
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))

# Recalculate deltas on hourly data
dt_hourly <- dt_hourly %>%
  mutate(
    Q_buf_delta = Q_buf - lag(Q_buf),
    temp_co_delta = temp_co - lag(temp_co),
    temp_home_delta = temp_home - lag(temp_home)
  )
```

## Feature Engineering

```{r feature-engineering}
# Calculate heat demand
dt_hourly <- dt_hourly %>%
  mutate(heat_demand_kwh = ifelse(discharging_cycle == 1 & heating_cycle == 0, -Q_buf_delta, 0))

# Create lagged features
dt_hourly <- dt_hourly %>%
  mutate(
    temp_lag1 = lag(temp, 1),
    heat_demand_kwh_lag1 = lag(heat_demand_kwh, 1)
  )

# Identify sign changes in Q_buf_delta
dt_hourly <- dt_hourly %>%
  mutate(sign_change = sign(Q_buf_delta) != lag(sign(Q_buf_delta)))

# Create cycle groups
dt_hourly$cycle_group <- cumsum(ifelse(is.na(dt_hourly$sign_change), 0, dt_hourly$sign_change))

# Find peaks (end of charge) and valleys (end of discharge)
peaks <- dt_hourly %>%
  group_by(cycle_group) %>%
  filter(Q_buf_delta > 0) %>%
  filter(date == max(date)) %>%
  ungroup() %>%
  select(peak_time = date, peak_q = Q_buf, cycle_group)

valleys <- dt_hourly %>%
  group_by(cycle_group) %>%
  filter(Q_buf_delta < 0) %>%
  filter(date == max(date)) %>%
  ungroup() %>%
  select(valley_time = date, valley_q = Q_buf, cycle_group)

# Pair peaks with the next valley using a rolling join
cycles <- data.table::as.data.table(peaks)[, .SD[1], by = peak_time] # Ensure unique peaks
valleys_dt <- data.table::as.data.table(valleys)

cycles[, next_valley_time := valleys_dt[cycles, on = .(valley_time > peak_time), x.valley_time, mult = "first"]]
cycles <- cycles[!is.na(next_valley_time)]

# Calculate time_to_discharge and time_extended
dt_hourly <- dt_hourly %>%
  mutate(
    time_to_discharge = NA,
    time_extended = NA
  )

for (i in 1:nrow(cycles)) {
  charge_start <- if (i > 1) cycles$next_valley_time[i-1] else NA
  charge_end <- cycles$peak_time[i]
  discharge_end <- cycles$next_valley_time[i]
  
  # time_extended: from previous valley to peak
  if (!is.na(charge_start)) {
    dt_hourly$time_extended[dt_hourly$date >= charge_start & dt_hourly$date <= charge_end] <- 
      as.numeric(difftime(charge_end, charge_start, units = "hours"))
  }
  
  # time_to_discharge: from peak to next valley
  dt_hourly$time_to_discharge[dt_hourly$date >= charge_end & dt_hourly$date <= discharge_end] <- 
    as.numeric(difftime(discharge_end, charge_end, units = "hours"))
}

# Define thresholds and identify cycles
stove_threshold <- 66
radiator_threshold <- 28

dt_hourly <- dt_hourly %>%
  mutate(
    heating_cycle = ifelse(temp_piec > stove_threshold, 1, 0),
    discharging_cycle = ifelse(temp_co > radiator_threshold, 1, 0)
  )
```

## Save Data

```{r save-data}
# Save the processed data
feather::write_feather(dt_hourly, "/home/dsl/gemini/chrust_plus/gemini_upgrade/ml_model_data_hourly_demand.feather")

print("ETL script with demand features finished successfully!")
```